"""
æ•°æ®é‡‡é›†è°ƒåº¦æœåŠ¡
å®šæ—¶æ›´æ–°é’±åŒ…æ•°æ®
"""
import asyncio
from typing import List, Dict, Any, Optional
from datetime import datetime, timedelta
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.interval import IntervalTrigger
from apscheduler.triggers.cron import CronTrigger
from loguru import logger

from app.services.wallet_analyzer import WalletAnalyzer
from app.database import db
from app.config import config


class DataScheduler:
    """æ•°æ®é‡‡é›†è°ƒåº¦å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–è°ƒåº¦å™¨"""
        self.scheduler = AsyncIOScheduler()
        self.analyzer = WalletAnalyzer(use_mock=False)
        self.is_running = False
        
        # ä»é…ç½®è¯»å–æ›´æ–°é¢‘ç‡
        scheduler_config = config.get_config("system").get("scheduler", {})
        self.update_intervals = scheduler_config.get("update_intervals", {
            "active": 300,      # æ´»è·ƒé’±åŒ…ï¼š5 åˆ†é’Ÿ
            "normal": 1800,     # æ™®é€šé’±åŒ…ï¼š30 åˆ†é’Ÿ
            "inactive": 3600    # ä¸æ´»è·ƒé’±åŒ…ï¼š1 å°æ—¶
        })
        
        self.batch_size = scheduler_config.get("batch_size", 10)
        self.max_concurrent = scheduler_config.get("max_concurrent", 5)
    
    def start(self):
        """å¯åŠ¨è°ƒåº¦å™¨"""
        if self.is_running:
            logger.warning("è°ƒåº¦å™¨å·²åœ¨è¿è¡Œ")
            return
        
        logger.info("=" * 60)
        logger.info("å¯åŠ¨æ•°æ®é‡‡é›†è°ƒåº¦å™¨...")
        logger.info("=" * 60)
        
        # æ·»åŠ å®šæ—¶ä»»åŠ¡
        
        # 1. æ´»è·ƒé’±åŒ…æ›´æ–°ï¼ˆæ¯ 5 åˆ†é’Ÿï¼‰
        self.scheduler.add_job(
            self.update_active_wallets,
            trigger=IntervalTrigger(seconds=self.update_intervals["active"]),
            id="update_active_wallets",
            name="æ›´æ–°æ´»è·ƒé’±åŒ…",
            max_instances=1,
            coalesce=True
        )
        
        # 2. æ™®é€šé’±åŒ…æ›´æ–°ï¼ˆæ¯ 30 åˆ†é’Ÿï¼‰
        self.scheduler.add_job(
            self.update_normal_wallets,
            trigger=IntervalTrigger(seconds=self.update_intervals["normal"]),
            id="update_normal_wallets",
            name="æ›´æ–°æ™®é€šé’±åŒ…",
            max_instances=1,
            coalesce=True
        )
        
        # 3. ä¸æ´»è·ƒé’±åŒ…æ›´æ–°ï¼ˆæ¯ 1 å°æ—¶ï¼‰
        self.scheduler.add_job(
            self.update_inactive_wallets,
            trigger=IntervalTrigger(seconds=self.update_intervals["inactive"]),
            id="update_inactive_wallets",
            name="æ›´æ–°ä¸æ´»è·ƒé’±åŒ…",
            max_instances=1,
            coalesce=True
        )
        
        # 4. æ¸…ç†è¿‡æœŸæ•°æ®ï¼ˆæ¯å¤©å‡Œæ™¨ 3 ç‚¹ï¼‰
        self.scheduler.add_job(
            self.cleanup_old_data,
            trigger=CronTrigger(hour=3, minute=0),
            id="cleanup_old_data",
            name="æ¸…ç†è¿‡æœŸæ•°æ®",
            max_instances=1
        )
        
        # 5. ç»Ÿè®¡æŠ¥å‘Šï¼ˆæ¯å¤©æ—©ä¸Š 9 ç‚¹ï¼‰
        self.scheduler.add_job(
            self.generate_daily_report,
            trigger=CronTrigger(hour=9, minute=0),
            id="generate_daily_report",
            name="ç”Ÿæˆæ¯æ—¥æŠ¥å‘Š",
            max_instances=1
        )
        
        self.scheduler.start()
        self.is_running = True
        
        logger.info("âœ… è°ƒåº¦å™¨å¯åŠ¨æˆåŠŸ")
        logger.info(f"æ´»è·ƒé’±åŒ…æ›´æ–°é—´éš”: {self.update_intervals['active']} ç§’")
        logger.info(f"æ™®é€šé’±åŒ…æ›´æ–°é—´éš”: {self.update_intervals['normal']} ç§’")
        logger.info(f"ä¸æ´»è·ƒé’±åŒ…æ›´æ–°é—´éš”: {self.update_intervals['inactive']} ç§’")
        logger.info("=" * 60)
    
    def stop(self):
        """åœæ­¢è°ƒåº¦å™¨"""
        if not self.is_running:
            return
        
        logger.info("åœæ­¢æ•°æ®é‡‡é›†è°ƒåº¦å™¨...")
        self.scheduler.shutdown()
        self.is_running = False
        logger.info("âœ… è°ƒåº¦å™¨å·²åœæ­¢")
    
    async def update_active_wallets(self):
        """æ›´æ–°æ´»è·ƒé’±åŒ…"""
        try:
            logger.info("ğŸ”„ å¼€å§‹æ›´æ–°æ´»è·ƒé’±åŒ…...")
            
            # è·å–éœ€è¦æ›´æ–°çš„æ´»è·ƒé’±åŒ…
            wallets = db.fetch_all("""
                SELECT address, last_updated 
                FROM wallets 
                WHERE update_frequency = 'active'
                ORDER BY last_updated ASC NULLS FIRST
                LIMIT ?
            """, (self.batch_size,))
            
            if not wallets:
                logger.info("æ²¡æœ‰éœ€è¦æ›´æ–°çš„æ´»è·ƒé’±åŒ…")
                return
            
            addresses = [w["address"] for w in wallets]
            logger.info(f"å‡†å¤‡æ›´æ–° {len(addresses)} ä¸ªæ´»è·ƒé’±åŒ…")
            
            # æ‰¹é‡æ›´æ–°
            results = await self.analyzer.batch_analyze_wallets(
                addresses,
                max_concurrent=self.max_concurrent
            )
            
            success_count = len([r for r in results if r])
            logger.info(f"âœ… æ´»è·ƒé’±åŒ…æ›´æ–°å®Œæˆ: {success_count}/{len(addresses)}")
            
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°æ´»è·ƒé’±åŒ…å¤±è´¥: {e}")
    
    async def update_normal_wallets(self):
        """æ›´æ–°æ™®é€šé’±åŒ…"""
        try:
            logger.info("ğŸ”„ å¼€å§‹æ›´æ–°æ™®é€šé’±åŒ…...")
            
            wallets = db.fetch_all("""
                SELECT address, last_updated 
                FROM wallets 
                WHERE update_frequency = 'normal'
                ORDER BY last_updated ASC NULLS FIRST
                LIMIT ?
            """, (self.batch_size,))
            
            if not wallets:
                logger.info("æ²¡æœ‰éœ€è¦æ›´æ–°çš„æ™®é€šé’±åŒ…")
                return
            
            addresses = [w["address"] for w in wallets]
            logger.info(f"å‡†å¤‡æ›´æ–° {len(addresses)} ä¸ªæ™®é€šé’±åŒ…")
            
            results = await self.analyzer.batch_analyze_wallets(
                addresses,
                max_concurrent=self.max_concurrent
            )
            
            success_count = len([r for r in results if r])
            logger.info(f"âœ… æ™®é€šé’±åŒ…æ›´æ–°å®Œæˆ: {success_count}/{len(addresses)}")
            
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°æ™®é€šé’±åŒ…å¤±è´¥: {e}")
    
    async def update_inactive_wallets(self):
        """æ›´æ–°ä¸æ´»è·ƒé’±åŒ…"""
        try:
            logger.info("ğŸ”„ å¼€å§‹æ›´æ–°ä¸æ´»è·ƒé’±åŒ…...")
            
            wallets = db.fetch_all("""
                SELECT address, last_updated 
                FROM wallets 
                WHERE update_frequency = 'inactive'
                ORDER BY last_updated ASC NULLS FIRST
                LIMIT ?
            """, (self.batch_size // 2,))  # ä¸æ´»è·ƒé’±åŒ…æ›´æ–°æ•°é‡å‡åŠ
            
            if not wallets:
                logger.info("æ²¡æœ‰éœ€è¦æ›´æ–°çš„ä¸æ´»è·ƒé’±åŒ…")
                return
            
            addresses = [w["address"] for w in wallets]
            logger.info(f"å‡†å¤‡æ›´æ–° {len(addresses)} ä¸ªä¸æ´»è·ƒé’±åŒ…")
            
            results = await self.analyzer.batch_analyze_wallets(
                addresses,
                max_concurrent=self.max_concurrent
            )
            
            success_count = len([r for r in results if r])
            logger.info(f"âœ… ä¸æ´»è·ƒé’±åŒ…æ›´æ–°å®Œæˆ: {success_count}/{len(addresses)}")
            
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°ä¸æ´»è·ƒé’±åŒ…å¤±è´¥: {e}")
    
    async def update_wallet_frequency(self):
        """
        æ ¹æ®é’±åŒ…æ´»è·ƒåº¦è‡ªåŠ¨è°ƒæ•´æ›´æ–°é¢‘ç‡
        - é«˜è¯„åˆ†ä¸”æœ€è¿‘æœ‰äº¤æ˜“ -> active
        - ä¸­ç­‰è¯„åˆ†æˆ–æœ‰ä¸€å®šäº¤æ˜“ -> normal
        - ä½è¯„åˆ†æˆ–é•¿æ—¶é—´æ— äº¤æ˜“ -> inactive
        """
        try:
            logger.info("ğŸ”„ è°ƒæ•´é’±åŒ…æ›´æ–°é¢‘ç‡...")
            
            # æ´»è·ƒé’±åŒ…ï¼šè¯„åˆ† > 80 ä¸”æœ€è¿‘ 24 å°æ—¶æœ‰äº¤æ˜“
            db.execute("""
                UPDATE wallets 
                SET update_frequency = 'active'
                WHERE smart_money_score >= 80
                AND (julianday('now') - julianday(last_updated)) < 1
            """)
            
            # æ™®é€šé’±åŒ…ï¼šè¯„åˆ† 60-80 æˆ–æœ€è¿‘ 7 å¤©æœ‰äº¤æ˜“
            db.execute("""
                UPDATE wallets 
                SET update_frequency = 'normal'
                WHERE (smart_money_score >= 60 AND smart_money_score < 80)
                OR (julianday('now') - julianday(last_updated)) < 7
            """)
            
            # ä¸æ´»è·ƒé’±åŒ…ï¼šè¯„åˆ† < 60 ä¸”è¶…è¿‡ 7 å¤©æ— æ›´æ–°
            db.execute("""
                UPDATE wallets 
                SET update_frequency = 'inactive'
                WHERE smart_money_score < 60
                AND (julianday('now') - julianday(last_updated)) >= 7
            """)
            
            logger.info("âœ… é’±åŒ…æ›´æ–°é¢‘ç‡è°ƒæ•´å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ è°ƒæ•´æ›´æ–°é¢‘ç‡å¤±è´¥: {e}")
    
    async def cleanup_old_data(self):
        """æ¸…ç†è¿‡æœŸæ•°æ®"""
        try:
            logger.info("ğŸ§¹ å¼€å§‹æ¸…ç†è¿‡æœŸæ•°æ®...")
            
            # æ¸…ç† 30 å¤©å‰çš„é€šçŸ¥
            result = db.execute("""
                DELETE FROM notifications 
                WHERE created_at < datetime('now', '-30 days')
            """)
            logger.info(f"æ¸…ç†äº† {result.rowcount} æ¡è¿‡æœŸé€šçŸ¥")
            
            # æ¸…ç†è¿‡æœŸçš„ AI ç¼“å­˜
            result = db.execute("""
                DELETE FROM ai_analysis_cache 
                WHERE expires_at < datetime('now')
            """)
            logger.info(f"æ¸…ç†äº† {result.rowcount} æ¡è¿‡æœŸ AI ç¼“å­˜")
            
            logger.info("âœ… æ•°æ®æ¸…ç†å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ æ•°æ®æ¸…ç†å¤±è´¥: {e}")
    
    async def generate_daily_report(self):
        """ç”Ÿæˆæ¯æ—¥ç»Ÿè®¡æŠ¥å‘Š"""
        try:
            logger.info("ğŸ“Š ç”Ÿæˆæ¯æ—¥ç»Ÿè®¡æŠ¥å‘Š...")
            
            # ç»Ÿè®¡æ€»é’±åŒ…æ•°
            total_wallets = db.fetch_one("SELECT COUNT(*) as count FROM wallets")
            total_count = total_wallets["count"] if total_wallets else 0
            
            # ç»Ÿè®¡å„ç­‰çº§é’±åŒ…æ•°
            grade_stats = db.fetch_all("""
                SELECT score_grade, COUNT(*) as count 
                FROM wallets 
                GROUP BY score_grade 
                ORDER BY score_grade
            """)
            
            # ç»Ÿè®¡ä»Šæ—¥æ›´æ–°æ•°
            today_updates = db.fetch_one("""
                SELECT COUNT(*) as count 
                FROM wallets 
                WHERE date(last_updated) = date('now')
            """)
            today_count = today_updates["count"] if today_updates else 0
            
            # ç»Ÿè®¡å¹³å‡è¯„åˆ†
            avg_score = db.fetch_one("""
                SELECT AVG(smart_money_score) as avg_score 
                FROM wallets 
                WHERE smart_money_score > 0
            """)
            avg = avg_score["avg_score"] if avg_score and avg_score["avg_score"] else 0
            
            # è¾“å‡ºæŠ¥å‘Š
            logger.info("=" * 60)
            logger.info("ğŸ“Š æ¯æ—¥ç»Ÿè®¡æŠ¥å‘Š")
            logger.info("=" * 60)
            logger.info(f"æ€»é’±åŒ…æ•°: {total_count}")
            logger.info(f"ä»Šæ—¥æ›´æ–°: {today_count}")
            logger.info(f"å¹³å‡è¯„åˆ†: {avg:.2f}")
            logger.info("\nç­‰çº§åˆ†å¸ƒ:")
            for stat in grade_stats:
                logger.info(f"  {stat['score_grade']} çº§: {stat['count']} ä¸ª")
            logger.info("=" * 60)
            
            # åˆ›å»ºç³»ç»Ÿé€šçŸ¥
            db.execute("""
                INSERT INTO notifications 
                (type, title, content, level, created_at)
                VALUES (?, ?, ?, ?, ?)
            """, (
                "system_report",
                "æ¯æ—¥ç»Ÿè®¡æŠ¥å‘Š",
                f"æ€»é’±åŒ…æ•°: {total_count}, ä»Šæ—¥æ›´æ–°: {today_count}, å¹³å‡è¯„åˆ†: {avg:.2f}",
                "info",
                datetime.now().isoformat()
            ))
            
        except Exception as e:
            logger.error(f"âŒ ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}")
    
    async def add_wallet(self, address: str, frequency: str = "normal"):
        """
        æ·»åŠ æ–°é’±åŒ…åˆ°ç›‘æ§åˆ—è¡¨
        
        Args:
            address: é’±åŒ…åœ°å€
            frequency: æ›´æ–°é¢‘ç‡ (active/normal/inactive)
        """
        try:
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
            existing = db.fetch_one(
                "SELECT id FROM wallets WHERE address = ?",
                (address,)
            )
            
            if existing:
                logger.info(f"é’±åŒ…å·²å­˜åœ¨: {address}")
                return
            
            # ç«‹å³åˆ†æé’±åŒ…
            logger.info(f"æ·»åŠ æ–°é’±åŒ…: {address}")
            result = await self.analyzer.analyze_wallet(address)
            
            if result:
                # æ›´æ–°é¢‘ç‡
                db.execute(
                    "UPDATE wallets SET update_frequency = ? WHERE address = ?",
                    (frequency, address)
                )
                logger.info(f"âœ… é’±åŒ…æ·»åŠ æˆåŠŸ: {address}, è¯„åˆ†: {result['score']}")
            else:
                logger.error(f"âŒ é’±åŒ…åˆ†æå¤±è´¥: {address}")
            
        except Exception as e:
            logger.error(f"âŒ æ·»åŠ é’±åŒ…å¤±è´¥ {address}: {e}")
    
    async def remove_wallet(self, address: str):
        """ä»ç›‘æ§åˆ—è¡¨ç§»é™¤é’±åŒ…"""
        try:
            db.execute("DELETE FROM wallets WHERE address = ?", (address,))
            logger.info(f"âœ… é’±åŒ…å·²ç§»é™¤: {address}")
        except Exception as e:
            logger.error(f"âŒ ç§»é™¤é’±åŒ…å¤±è´¥ {address}: {e}")
    
    def get_scheduler_status(self) -> Dict[str, Any]:
        """è·å–è°ƒåº¦å™¨çŠ¶æ€"""
        jobs = []
        for job in self.scheduler.get_jobs():
            jobs.append({
                "id": job.id,
                "name": job.name,
                "next_run_time": job.next_run_time.isoformat() if job.next_run_time else None,
                "trigger": str(job.trigger)
            })
        
        return {
            "is_running": self.is_running,
            "jobs": jobs,
            "update_intervals": self.update_intervals,
            "batch_size": self.batch_size,
            "max_concurrent": self.max_concurrent
        }


# å…¨å±€è°ƒåº¦å™¨å®ä¾‹
scheduler = DataScheduler()

